{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sklearn.naive_bayes as NB\n",
    "import sklearn.model_selection as cv\n",
    "import sklearn.metrics as m\n",
    "from sklearn import preprocessing\n",
    "from statsmodels.stats.proportion import proportion_confint\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Naive Bayes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read the data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As usual, before analyzing the data we read the csv and store all the values in a variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('../datasets/preprocessed/train.csv', sep=',', na_values=\"NA\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MSSubClass</th>\n",
       "      <th>MSZoning</th>\n",
       "      <th>LotArea</th>\n",
       "      <th>LotShape</th>\n",
       "      <th>LandContour</th>\n",
       "      <th>LotConfig</th>\n",
       "      <th>Neighborhood</th>\n",
       "      <th>Condition1</th>\n",
       "      <th>BldgType</th>\n",
       "      <th>HouseStyle</th>\n",
       "      <th>...</th>\n",
       "      <th>MiscVal</th>\n",
       "      <th>SaleType</th>\n",
       "      <th>SaleCondition</th>\n",
       "      <th>SalePrice</th>\n",
       "      <th>MasVnr</th>\n",
       "      <th>SecondFloor</th>\n",
       "      <th>Baths</th>\n",
       "      <th>Porch</th>\n",
       "      <th>Pool</th>\n",
       "      <th>Id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>G</td>\n",
       "      <td>RH</td>\n",
       "      <td>0.185945</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>Inside</td>\n",
       "      <td>Edwards</td>\n",
       "      <td>Artery</td>\n",
       "      <td>1Fam</td>\n",
       "      <td>2Story</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "      <td>Level2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.4</td>\n",
       "      <td>True</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A</td>\n",
       "      <td>RL</td>\n",
       "      <td>0.198890</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>Inside</td>\n",
       "      <td>NAmes</td>\n",
       "      <td>Norm</td>\n",
       "      <td>1Fam</td>\n",
       "      <td>1Story</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>WD</td>\n",
       "      <td>Family</td>\n",
       "      <td>Level2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>True</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>L</td>\n",
       "      <td>RL</td>\n",
       "      <td>0.260616</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>Corner</td>\n",
       "      <td>NridgHt</td>\n",
       "      <td>Norm</td>\n",
       "      <td>Twnhs</td>\n",
       "      <td>1Story</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>New</td>\n",
       "      <td>Partial</td>\n",
       "      <td>Level4</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.4</td>\n",
       "      <td>True</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>A</td>\n",
       "      <td>RL</td>\n",
       "      <td>0.251230</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>Inside</td>\n",
       "      <td>NAmes</td>\n",
       "      <td>Norm</td>\n",
       "      <td>1Fam</td>\n",
       "      <td>1Story</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>WD</td>\n",
       "      <td>Abnorml</td>\n",
       "      <td>Level1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>False</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>E</td>\n",
       "      <td>RL</td>\n",
       "      <td>0.174186</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>Inside</td>\n",
       "      <td>SWISU</td>\n",
       "      <td>Norm</td>\n",
       "      <td>1Fam</td>\n",
       "      <td>1.5Fin</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "      <td>Level2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.4</td>\n",
       "      <td>True</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 48 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  MSSubClass MSZoning   LotArea  LotShape LandContour LotConfig Neighborhood  \\\n",
       "0          G       RH  0.185945       1.0         Lvl    Inside      Edwards   \n",
       "1          A       RL  0.198890       1.0         Lvl    Inside        NAmes   \n",
       "2          L       RL  0.260616       1.0         Lvl    Corner      NridgHt   \n",
       "3          A       RL  0.251230       1.0         Lvl    Inside        NAmes   \n",
       "4          E       RL  0.174186       1.0         Lvl    Inside        SWISU   \n",
       "\n",
       "  Condition1 BldgType HouseStyle  ...  MiscVal  SaleType SaleCondition  \\\n",
       "0     Artery     1Fam     2Story  ...      0.0        WD        Normal   \n",
       "1       Norm     1Fam     1Story  ...      0.0        WD        Family   \n",
       "2       Norm    Twnhs     1Story  ...      0.0       New       Partial   \n",
       "3       Norm     1Fam     1Story  ...      0.0        WD       Abnorml   \n",
       "4       Norm     1Fam     1.5Fin  ...      0.0        WD        Normal   \n",
       "\n",
       "  SalePrice MasVnr  SecondFloor Baths  Porch Pool Id  \n",
       "0    Level2    0.0          1.0   0.4   True  0.0  0  \n",
       "1    Level2    1.0          0.0   0.0   True  0.0  1  \n",
       "2    Level4    1.0          0.0   0.4   True  0.0  2  \n",
       "3    Level1    1.0          0.0   0.0  False  0.0  3  \n",
       "4    Level2    0.0          1.0   0.4   True  0.0  4  \n",
       "\n",
       "[5 rows x 48 columns]"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare the data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, we begin by separating the data into two different variables: num_data, which only contains the numerical values, and cat_data, which only contains the categorical ones. We also exclude from cat_dat all the values that correspond to the column \"SalePrice\", since that's what we want to predict."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "data\n",
    "num_data = data.select_dtypes(include=np.number).drop(columns='Id')\n",
    "cat_data = data.select_dtypes(include=['bool','object']).drop(columns='SalePrice')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train a model with numeric columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, we train a model using the numerical values in num_data. We're using Gaussian Naive Bayes which, as we can see, gives us a very poor score, only 0.206."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.20642644731252324"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = num_data\n",
    "Y = data.loc[:,'SalePrice']\n",
    "\n",
    "X_train, X_test, y_train, y_test = cv.train_test_split(X, Y, test_size=.3, random_state=1)\n",
    "\n",
    "gnb = NB.GaussianNB()\n",
    "gnb.fit(X_train,y_train)\n",
    "pred=gnb.predict(X_test)\n",
    "m.f1_score(y_test, pred, average='macro')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train a model with categorical columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Afterwards, we train a model with the categorical values in cat_data. Since we're using Multinomial Naive Bayes, which requires numerical tags instead of strings, we need to preprocess the categories in order to assign an integer ID to each different one before doing the training. As we can see, the final score is now 0.5, which is times better than the previous score, but still has room for improvement."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5001072522982637"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = cat_data\n",
    "Y = data.loc[:,'SalePrice']\n",
    "\n",
    "data.dtypes\n",
    "for col in X.columns:\n",
    "    X.loc[:,col] = pd.factorize(X.loc[:,col])[0]\n",
    "X.head()\n",
    "\n",
    "X_train, X_test, y_train, y_test = cv.train_test_split(X, Y, test_size=.3, random_state=1)\n",
    "\n",
    "mnb = NB.MultinomialNB()\n",
    "mnb.fit(X_train,y_train)\n",
    "pred=mnb.predict(X_test)\n",
    "m.f1_score(y_test, pred, average='macro')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cross validation of the best model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we do cross validation with the categorical values, as it's the best model for now, applying the same preprocessing we did for the previous model and Multinomial Naive Bayes again, but now calculating the cross_val_score. As we can see, the result is 0.427. We also build the confusion matrix and compute the f1 score, which again has almost the same value, and then we finish with the classification report."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.4267319062102916"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kfold = cv.StratifiedKFold(n_splits=10, random_state=1) \n",
    "\n",
    "X = cat_data\n",
    "Y = data.loc[:,'SalePrice']\n",
    "\n",
    "for col in X.columns:\n",
    "    X.loc[:,col] = pd.factorize(X.loc[:,col])[0]\n",
    "X.head()\n",
    "\n",
    "mnb = NB.MultinomialNB()\n",
    "\n",
    "cvs = cv.cross_val_score(mnb,X=X,y=Y,cv=kfold,scoring='f1_macro')\n",
    "np.mean(cvs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 46  32   1   0   0]\n",
      " [ 61 403 132  14  18]\n",
      " [  2  46 154  10  11]\n",
      " [  0   7  30   5  17]\n",
      " [  0   1   4   3   9]]\n",
      "0.42740078633319734\n"
     ]
    }
   ],
   "source": [
    "pred = cv.cross_val_predict(mnb, X=X, y=Y, cv=kfold)  \n",
    "\n",
    "print(m.confusion_matrix(Y, pred))\n",
    "print(m.f1_score(Y, pred, average='macro'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "      Level1       0.42      0.58      0.49        79\n",
      "      Level2       0.82      0.64      0.72       628\n",
      "      Level3       0.48      0.69      0.57       223\n",
      "      Level4       0.16      0.08      0.11        59\n",
      "      Level5       0.16      0.53      0.25        17\n",
      "\n",
      "    accuracy                           0.61      1006\n",
      "   macro avg       0.41      0.51      0.43      1006\n",
      "weighted avg       0.67      0.61      0.63      1006\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(m.classification_report(Y, pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Balancing the dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Despite having an accuracy of 0.613, the data of some of the categories of SalePrice was poorly classified. Level4, for example, has an f1-score as low as 0.11. This is due to having an unbalanced dataset, so we decide to balance our data so that the amount of instances for each SalePrice category is more or less the same."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Level2    628\n",
       "Level3    223\n",
       "Level1     79\n",
       "Level4     59\n",
       "Level5     17\n",
       "Name: SalePrice, dtype: int64"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Level2' 'Level4' 'Level1' 'Level3' 'Level5']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Level1    237\n",
       "Level4    236\n",
       "Level3    223\n",
       "Level2    209\n",
       "Level5    170\n",
       "Name: SalePrice, dtype: int64"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(data['SalePrice'].unique())\n",
    "\n",
    "X1 = data[data['SalePrice'] == 'Level1']\n",
    "X2 = data[data['SalePrice'] == 'Level2']\n",
    "X3 = data[data['SalePrice'] == 'Level3']\n",
    "X4 = data[data['SalePrice'] == 'Level4']\n",
    "X5 = data[data['SalePrice'] == 'Level5']\n",
    "\n",
    "bdata = pd.DataFrame()\n",
    "\n",
    "for i in range(3):\n",
    "    bdata = bdata.append(X1, ignore_index = True)\n",
    "bdata = bdata.append(X2.sample(frac=1/3), ignore_index = True)\n",
    "bdata = bdata.append(X3, ignore_index = True)\n",
    "for i in range(4):\n",
    "    bdata = bdata.append(X4, ignore_index = True)\n",
    "for i in range(10):\n",
    "    bdata = bdata.append(X5, ignore_index = True)\n",
    "\n",
    "bdata['SalePrice'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By balancing the dataset, we can see that the scores and accuracy are lower than before doing so (0.556), but the f1-score for the different levels is more consistent, with smaller diferences between them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5670935699237525"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = bdata.select_dtypes(include=['bool','object']).drop(columns=['SalePrice'])\n",
    "Y = bdata['SalePrice']\n",
    "\n",
    "kfold = cv.StratifiedKFold(n_splits=10) \n",
    "\n",
    "for col in X.columns:\n",
    "    X.loc[:,col] = pd.factorize(X.loc[:,col])[0]\n",
    "X.head()\n",
    "\n",
    "mnb = NB.MultinomialNB()\n",
    "\n",
    "cvs = cv.cross_val_score(mnb,X=X,y=Y,cv=kfold, scoring='f1_macro')\n",
    "np.mean(cvs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[204  26   3   3   1]\n",
      " [ 52  88  51  14   4]\n",
      " [  5  43 100  57  18]\n",
      " [  0  19  51 112  54]\n",
      " [  0   0  20  38 112]]\n",
      "0.5667520980998336\n"
     ]
    }
   ],
   "source": [
    "pred = cv.cross_val_predict(mnb, X=X, y=Y, cv=kfold)  \n",
    "\n",
    "print(m.confusion_matrix(Y, pred))\n",
    "print(m.f1_score(Y, pred, average='macro'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "      Level1       0.78      0.86      0.82       237\n",
      "      Level2       0.50      0.42      0.46       209\n",
      "      Level3       0.44      0.45      0.45       223\n",
      "      Level4       0.50      0.47      0.49       236\n",
      "      Level5       0.59      0.66      0.62       170\n",
      "\n",
      "    accuracy                           0.57      1075\n",
      "   macro avg       0.56      0.57      0.57      1075\n",
      "weighted avg       0.57      0.57      0.57      1075\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(m.classification_report(Y, pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Naive Bayes using PCA "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using PCA we obtain better results than before. We have a final score of 0.54 with Gaussian Naive Bayes and 0.6 for the cross validation. This is an improvement, but the numbers are still a little bit lower than desired."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_pca = pd.read_csv('../datasets/preprocessed/train_pca.csv', sep=',', na_values=\"NA\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.753748</td>\n",
       "      <td>0.636941</td>\n",
       "      <td>-0.164025</td>\n",
       "      <td>-0.204247</td>\n",
       "      <td>0.549835</td>\n",
       "      <td>0.539191</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.117306</td>\n",
       "      <td>-0.688384</td>\n",
       "      <td>-0.493263</td>\n",
       "      <td>0.796882</td>\n",
       "      <td>-0.008604</td>\n",
       "      <td>-0.239237</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.787114</td>\n",
       "      <td>-0.469485</td>\n",
       "      <td>-0.626444</td>\n",
       "      <td>-0.272131</td>\n",
       "      <td>-0.467151</td>\n",
       "      <td>0.305142</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.172825</td>\n",
       "      <td>-0.708999</td>\n",
       "      <td>-0.480148</td>\n",
       "      <td>0.864432</td>\n",
       "      <td>0.145394</td>\n",
       "      <td>-0.106748</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.488369</td>\n",
       "      <td>0.642514</td>\n",
       "      <td>-0.179286</td>\n",
       "      <td>-0.202405</td>\n",
       "      <td>0.023691</td>\n",
       "      <td>-0.091447</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          0         1         2         3         4         5\n",
       "0 -0.753748  0.636941 -0.164025 -0.204247  0.549835  0.539191\n",
       "1 -0.117306 -0.688384 -0.493263  0.796882 -0.008604 -0.239237\n",
       "2  0.787114 -0.469485 -0.626444 -0.272131 -0.467151  0.305142\n",
       "3 -0.172825 -0.708999 -0.480148  0.864432  0.145394 -0.106748\n",
       "4 -0.488369  0.642514 -0.179286 -0.202405  0.023691 -0.091447"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = data_pca.drop(columns='Id')\n",
    "Y = data.loc[:,'SalePrice']\n",
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5373145386766076"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = cv.train_test_split(X, Y, test_size=.3, random_state=1)\n",
    "\n",
    "gnb = NB.GaussianNB()\n",
    "gnb.fit(X_train,y_train)\n",
    "pred=gnb.predict(X_test)\n",
    "m.f1_score(y_test, pred, average='macro')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5721330494202524"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cvs = cv.cross_val_score(gnb,X=X,y=Y,cv=kfold,scoring='f1_macro')\n",
    "np.mean(cvs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 35  44   0   0   0]\n",
      " [ 24 559  44   1   0]\n",
      " [  3  72 132  15   1]\n",
      " [  0   3  25  28   3]\n",
      " [  0   0   2   8   7]]\n",
      "0.5953451439334121\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "      Level1       0.56      0.44      0.50        79\n",
      "      Level2       0.82      0.89      0.86       628\n",
      "      Level3       0.65      0.59      0.62       223\n",
      "      Level4       0.54      0.47      0.50        59\n",
      "      Level5       0.64      0.41      0.50        17\n",
      "\n",
      "    accuracy                           0.76      1006\n",
      "   macro avg       0.64      0.56      0.60      1006\n",
      "weighted avg       0.75      0.76      0.75      1006\n",
      "\n"
     ]
    }
   ],
   "source": [
    "pred = cv.cross_val_predict(gnb, X=X, y=Y, cv=kfold)  \n",
    "\n",
    "print(m.confusion_matrix(Y, pred))\n",
    "print(m.f1_score(Y, pred, average='macro'))\n",
    "print(m.classification_report(Y, pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing with test dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_test_pca = pd.read_csv('../datasets/preprocessed/test_pca.csv', sep=',')\n",
    "data_test = pd.read_csv('../datasets/preprocessed/test.csv', sep=',')\n",
    "y_test = data_test['SalePrice']\n",
    "data_test_pca.drop(columns='Id',inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "      Level1       0.40      0.34      0.37        35\n",
      "      Level2       0.82      0.88      0.85       276\n",
      "      Level3       0.67      0.60      0.63        88\n",
      "      Level4       0.53      0.36      0.43        25\n",
      "      Level5       0.62      0.62      0.62         8\n",
      "\n",
      "    accuracy                           0.75       432\n",
      "   macro avg       0.61      0.56      0.58       432\n",
      "weighted avg       0.73      0.75      0.74       432\n",
      "\n",
      "F1 macro: 0.5808445264389472, Accuracy: 0.7453703703703703, Precision macro: 0.6081468164531976, Recall macro: 0.5621129305477132\n"
     ]
    }
   ],
   "source": [
    "pred = cv.cross_val_predict(gnb, X=data_test_pca, y=y_test, cv=kfold)  \n",
    "print(m.classification_report(y_test, pred))\n",
    "accuracy = m.accuracy_score(y_test, pred)\n",
    "precision = m.precision_score(y_test, pred, average='macro')\n",
    "recall = m.recall_score(y_test, pred, average='macro')\n",
    "f1 = m.f1_score(y_test, pred, average='macro')\n",
    "print('F1 macro: ' + str(f1) + ', Accuracy: ' + str(accuracy) + ', Precision macro: ' + str(precision) + ', Recall macro: ' + str(recall))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confidence interval:  (0.5312718255649439, 0.625091645922958)\n"
     ]
    }
   ],
   "source": [
    "epsilon = m.f1_score(y_test, pred, average='macro')\n",
    "print(\"Confidence interval: \",proportion_confint(count=epsilon*data_test_pca.shape[0], nobs=data_test_pca.shape[0], alpha=0.05, method='binom_test'))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
